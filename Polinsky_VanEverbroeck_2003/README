# Some notes on how to reproduce the Vulgar Latin -> Old French results
# reported in Polinsky & Van Everbroeck (2003).

_ The file latin_corpus contains the 500 Latin words which we used in our
simulations. For each word, the first line contains the phonological form,
the Latin gender, three frequency measures, and the equivalent Celtic
gender. The following lines then contain the syllabified phonological forms
for the different case/number combinations of the noun itself, as well as
just the noun ending, and the suffixes for the approriately conjugated
demonstrative and adjective.

_ You can use generate_pat_file.pl (a Perl program) to turn latin_corpus
into a form our neural network simulator package (SNNS) could understand.
The program expects the corpus file as well as the name for the output file
as its command line arguments, but it will ask for them if you don't specify
any arguments. If you are planning to use a different network package you
will undoubtedly have to edit this file to get things into a format it can
understand.

_ 346-30-3.net is the SNNS network file used by our simulations. The name
refers to the number of input, hidden, and output units.

_ generate_sim_files.pl is a Perl program which creates useful files for
running the diachronic simulation runs. It creates a UNIX shell script
(sh.mox) which can be run to simulate 10 generations, as well as 10 SNNS
batch learning scripts, one for each generation (mox0 -> mox9).

_ If you look at sh.mox, you'll see that the steps for each generation are
identical: 
	. run batchman, the SNNS command line utility, to train the network
        . run res2pat, a C program, to convert the network's output into the
          training patterns for the next generation
        . run analyze_res_file.pl, a Perl program, to generate a rough
          analysis file (.cmp) to let you see how the network is treating
          the nouns in this generation
	. compress the (relatively) big SNNS .pat and .res files to save
	  disk space

_ The source for res2pat can be found in res2pat.c. You will have to compile
it on your platform. It does the math to clean up one generation's uncertain
output (e.g. 0.8 feminine, 0.2 masculine) into a clean signal for the next
generation of learners (e.g. 1.0 feminine).

_ The analyze_res_file.pl program produces an output file which just lists
how the network is classifying each noun case/number combination, e.g. the
Accusative Singular form of 'ador' is originally neuter, but the network now
categorizes it as masculine (i.e. n -> f). At the bottom of the .cmp file,
you will also find some summary numbers as to how many nouns of each gender
are classified into nouns of another gender.

_ The file moxtest.tgt is used by analyze_res_file.pl to generate its .cmp
output file. It just lists the nouns with their original gender and the
case/number combinations which are attested for them. (This could be
reconstructed on the fly from the .res file but it would take some more CPU
cycles.)

_ The file declensions.tgt is identical to moxtest.tgt but contains an extra
field for each Latin noun specifying its declension class. It is used by
analyze_cmp_files.pl, another Perl program, which parses all the .cmp files
generated by analyze_res.pl in order to see how the genders changed for each
specific declension. The output currently just gets sent to STDOUT but can
be redirected to a file.

